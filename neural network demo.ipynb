{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 首先我用一个简单的demo为你展示神经网络训练的过程：\n",
    "   - 数据准备\n",
    "   - 网络搭建\n",
    "   - 利用反向传播算法迭代更新参数：\n",
    "      - optimizer.zero_grad() 清空过往梯度；\n",
    "      - loss.backward() 反向传播，计算当前梯度；\n",
    "      - optimizer.step() 根据梯度更新网络参数\n",
    "2. 然后我已以mnist为例为你展示一个稍复杂一点的网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " x:tensor([[-1., -1.],\n",
      "        [-2., -3.],\n",
      "        [ 3.,  2.],\n",
      "        [ 3.,  4.]]) \n",
      " y:tensor([-1., -1.,  1.,  1.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#前两个样本标签是一类，标签为0;后两个样本是一类，标签为1\n",
    "sample_num=2\n",
    "x=torch.tensor([[-1,-1.0],#-1.0是让数据类型变成float，而不是int\n",
    "                [-2,-3],\n",
    "                [3,2],\n",
    "                [3,4]])\n",
    "y=torch.tensor([-1.0,-1,1,1])\n",
    "\n",
    "print(' x:{} \\n y:{}'.format(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 网络搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(net,self).__init__()\n",
    "        self.layer1=nn.Linear(2,5)#输入数据的维度为2，输出的维度为5\n",
    "        self.layer2=nn.Linear(5,1)\n",
    "        self.activation=nn.ReLU()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x1=self.layer1(x)\n",
    "        x2=self.activation(x1)\n",
    "        y_pred=self.layer2(x2)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train\n",
    "\n",
    "- 这个demo有问题，很可能达不到很好的准确率，这里只是让你了解宏观框架"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0 loss: 1.0473737716674805 acc:0.0\n",
      "epoch1 loss: 1.0472602844238281 acc:0.0\n",
      "epoch2 loss: 1.047147274017334 acc:0.0\n",
      "epoch3 loss: 1.047034740447998 acc:0.0\n",
      "epoch4 loss: 1.0469223260879517 acc:0.0\n",
      "epoch5 loss: 1.046810507774353 acc:0.0\n",
      "epoch6 loss: 1.046699047088623 acc:0.0\n",
      "epoch7 loss: 1.0465879440307617 acc:0.0\n",
      "epoch8 loss: 1.046477198600769 acc:0.0\n",
      "epoch9 loss: 1.0463670492172241 acc:0.0\n",
      "epoch10 loss: 1.0462568998336792 acc:0.0\n",
      "epoch11 loss: 1.0461472272872925 acc:0.0\n",
      "epoch12 loss: 1.046038031578064 acc:0.0\n",
      "epoch13 loss: 1.0459290742874146 acc:0.0\n",
      "epoch14 loss: 1.045820713043213 acc:0.0\n",
      "epoch15 loss: 1.0457124710083008 acc:0.0\n",
      "epoch16 loss: 1.0456045866012573 acc:0.0\n",
      "epoch17 loss: 1.0454972982406616 acc:0.0\n",
      "epoch18 loss: 1.045390248298645 acc:0.0\n",
      "epoch19 loss: 1.0452836751937866 acc:0.0\n",
      "epoch20 loss: 1.0451774597167969 acc:0.0\n",
      "epoch21 loss: 1.0450713634490967 acc:0.0\n",
      "epoch22 loss: 1.0449657440185547 acc:0.0\n",
      "epoch23 loss: 1.044860601425171 acc:0.0\n",
      "epoch24 loss: 1.0447556972503662 acc:0.0\n",
      "epoch25 loss: 1.0446511507034302 acc:0.0\n",
      "epoch26 loss: 1.0445469617843628 acc:0.0\n",
      "epoch27 loss: 1.0444432497024536 acc:0.0\n",
      "epoch28 loss: 1.044339656829834 acc:0.0\n",
      "epoch29 loss: 1.0442365407943726 acc:0.0\n",
      "epoch30 loss: 1.0441336631774902 acc:0.0\n",
      "epoch31 loss: 1.0440312623977661 acc:0.0\n",
      "epoch32 loss: 1.043929100036621 acc:0.0\n",
      "epoch33 loss: 1.0438275337219238 acc:0.0\n",
      "epoch34 loss: 1.0437262058258057 acc:0.0\n",
      "epoch35 loss: 1.0436251163482666 acc:0.0\n",
      "epoch36 loss: 1.0435243844985962 acc:0.0\n",
      "epoch37 loss: 1.0434238910675049 acc:0.0\n",
      "epoch38 loss: 1.0433239936828613 acc:0.0\n",
      "epoch39 loss: 1.0432240962982178 acc:0.0\n",
      "epoch40 loss: 1.0431249141693115 acc:0.0\n",
      "epoch41 loss: 1.0430257320404053 acc:0.0\n",
      "epoch42 loss: 1.0429272651672363 acc:0.0\n",
      "epoch43 loss: 1.0428286790847778 acc:0.0\n",
      "epoch44 loss: 1.0427308082580566 acc:0.0\n",
      "epoch45 loss: 1.042633056640625 acc:0.0\n",
      "epoch46 loss: 1.0425355434417725 acc:0.0\n",
      "epoch47 loss: 1.0424386262893677 acc:0.0\n",
      "epoch48 loss: 1.0423418283462524 acc:0.0\n",
      "epoch49 loss: 1.0422455072402954 acc:0.0\n",
      "epoch50 loss: 1.0421494245529175 acc:0.0\n",
      "epoch51 loss: 1.0420536994934082 acc:0.0\n",
      "epoch52 loss: 1.041958212852478 acc:0.0\n",
      "epoch53 loss: 1.041862964630127 acc:0.0\n",
      "epoch54 loss: 1.0417683124542236 acc:0.0\n",
      "epoch55 loss: 1.0416738986968994 acc:0.0\n",
      "epoch56 loss: 1.0415794849395752 acc:0.0\n",
      "epoch57 loss: 1.0414857864379883 acc:0.0\n",
      "epoch58 loss: 1.041392207145691 acc:0.0\n",
      "epoch59 loss: 1.0412989854812622 acc:0.0\n",
      "epoch60 loss: 1.0412061214447021 acc:0.0\n",
      "epoch61 loss: 1.0411134958267212 acc:0.0\n",
      "epoch62 loss: 1.0410212278366089 acc:0.0\n",
      "epoch63 loss: 1.0409293174743652 acc:0.0\n",
      "epoch64 loss: 1.0408376455307007 acc:0.0\n",
      "epoch65 loss: 1.0407460927963257 acc:0.0\n",
      "epoch66 loss: 1.0406548976898193 acc:0.0\n",
      "epoch67 loss: 1.0405641794204712 acc:0.0\n",
      "epoch68 loss: 1.0404738187789917 acc:0.0\n",
      "epoch69 loss: 1.0403835773468018 acc:0.0\n",
      "epoch70 loss: 1.04029381275177 acc:0.0\n",
      "epoch71 loss: 1.0402041673660278 acc:0.0\n",
      "epoch72 loss: 1.0401148796081543 acc:0.0\n",
      "epoch73 loss: 1.0400258302688599 acc:0.0\n",
      "epoch74 loss: 1.039937138557434 acc:0.0\n",
      "epoch75 loss: 1.039848804473877 acc:0.0\n",
      "epoch76 loss: 1.0397605895996094 acc:0.0\n",
      "epoch77 loss: 1.0396728515625 acc:0.0\n",
      "epoch78 loss: 1.0395853519439697 acc:0.0\n",
      "epoch79 loss: 1.0394980907440186 acc:0.0\n",
      "epoch80 loss: 1.039411187171936 acc:0.0\n",
      "epoch81 loss: 1.039324402809143 acc:0.0\n",
      "epoch82 loss: 1.0392382144927979 acc:0.0\n",
      "epoch83 loss: 1.0391521453857422 acc:0.0\n",
      "epoch84 loss: 1.0390660762786865 acc:0.0\n",
      "epoch85 loss: 1.0389807224273682 acc:0.0\n",
      "epoch86 loss: 1.0388953685760498 acc:0.0\n",
      "epoch87 loss: 1.0388104915618896 acc:0.0\n",
      "epoch88 loss: 1.0387258529663086 acc:0.0\n",
      "epoch89 loss: 1.038641333580017 acc:0.0\n",
      "epoch90 loss: 1.0385574102401733 acc:0.0\n",
      "epoch91 loss: 1.0384736061096191 acc:0.0\n",
      "epoch92 loss: 1.0383899211883545 acc:0.0\n",
      "epoch93 loss: 1.0383063554763794 acc:0.0\n",
      "epoch94 loss: 1.0382235050201416 acc:0.0\n",
      "epoch95 loss: 1.038140892982483 acc:0.0\n",
      "epoch96 loss: 1.0380584001541138 acc:0.0\n",
      "epoch97 loss: 1.0379760265350342 acc:0.0\n",
      "epoch98 loss: 1.0378942489624023 acc:0.0\n",
      "epoch99 loss: 1.0378124713897705 acc:0.0\n"
     ]
    }
   ],
   "source": [
    "model=net()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)#这里定义了一个优化器,用来更新权重\n",
    "\n",
    "for epoch in range(0,100):\n",
    "    #清空之前内存里的梯度,如果不请空之前的梯度，梯度会一直累加\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #将数据x输入到网络中，得到预测值。输入shape为(4,2)，输出shape为(4,1),4代表4条数据\n",
    "    y_pred=model.forward(x)\n",
    "    \n",
    "    #这是我自己定义的损失函数，使用平方误差\n",
    "    loss=torch.mean((y_pred-y)**2)\n",
    "    \n",
    "    #这行代码将自动计算各个变量的梯度，从loss开始一直到输入x，中间变量的梯度都会计算并暂存\n",
    "    loss.backward()\n",
    "    \n",
    "    #这行代码将利用暂存的梯度去更新网络权重\n",
    "    optimizer.step()\n",
    "    \n",
    "    #这是计算准确率\n",
    "    accuracy=(torch.sum(y_pred[:sample_num]<0)+torch.sum(y_pred[sample_num:]>0)).float()/(sample_num*2)\n",
    "    print('epoch{} loss: {} acc:{}'.format(epoch,loss.item(),accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mnsit分类demo\n",
    "\n",
    "- 参考网址：https://www.jianshu.com/p/ade6f9456ec5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff2d210e748>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BATCH_SIZE=512 #每次打包512个数据，一起扔进网络\n",
    "EPOCHS=5 # 总共训练的轮数\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # 让torch判断是否使用GPU\n",
    "\n",
    "#train_loader和test_loader使用pytorch内置的函数获取mnist数据，一开始会自动下载数据\n",
    "#document:https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader\n",
    "#遇到不会的，你就优先查官方的documentation\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('data', train=True, download=True, #有数据集后改为download=False\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))#transform里面定义了对数据的预处理函数\n",
    "                       ])),\n",
    "        batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('data', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "#为你绘制一个数字\n",
    "plt.imshow(train_loader.dataset.data[0,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 网络搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 二维卷积操作，输入通道为1，输出通道为10(意味着有10个卷积核，每次卷积核生成一个通道的数据)\n",
    "        # 卷积核的大小是5*5的\n",
    "        self.conv1=nn.Conv2d(1,10,5) \n",
    "        self.conv2=nn.Conv2d(10,20,3)\n",
    "        \n",
    "        #全连接层，输入是2000维向量，输出是500维向量\n",
    "        self.fc1 = nn.Linear(20*10*10,500)\n",
    "        self.fc2 = nn.Linear(500,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # 输入数据shape: 512,1,28,28 \n",
    "        #其中521是batch_size,\n",
    "        #1是一个颜色通道，这是灰度图，不是彩色的，只有一个通道\n",
    "        #28,28分别是每幅图的长与宽\n",
    "        in_size = x.size(0)#in_size=512\n",
    "        out = self.conv1(x)\n",
    "        out = F.relu(out)# relu是一种激活函数\n",
    "        out = F.max_pool2d(out, 2, 2)  #最大池化操作，在2*2范围内找最大的那个值\n",
    "        out = self.conv2(out)\n",
    "        out = F.relu(out)\n",
    "        out = out.view(in_size,-1)#view函数可以改变数据的shape，in_size=512,-1代表自动确定维度，这里将数据变成(512,?)的矩阵，?根据数据自动确定\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = F.log_softmax(out,dim=1)# 文档：https://pytorch.org/docs/stable/nn.functional.html?highlight=log_softmax#torch.nn.functional.log_softmax\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train\n",
    "我们在训练集上迭代更新网络参数，紧接着在测试集上测试网络的性能，可以看到经过5轮迭代，网络的能在测试集上达到99%的准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [14848/60000 (25%)]\tLoss: 0.206701\n",
      "Train Epoch: 1 [30208/60000 (50%)]\tLoss: 0.164792\n",
      "Train Epoch: 1 [45568/60000 (75%)]\tLoss: 0.129204\n",
      "\n",
      "Test set: Average loss: 0.0793, Accuracy: 9762/10000 (98%)\n",
      "\n",
      "Train Epoch: 2 [14848/60000 (25%)]\tLoss: 0.065975\n",
      "Train Epoch: 2 [30208/60000 (50%)]\tLoss: 0.070608\n",
      "Train Epoch: 2 [45568/60000 (75%)]\tLoss: 0.050992\n",
      "\n",
      "Test set: Average loss: 0.0585, Accuracy: 9798/10000 (98%)\n",
      "\n",
      "Train Epoch: 3 [14848/60000 (25%)]\tLoss: 0.048688\n",
      "Train Epoch: 3 [30208/60000 (50%)]\tLoss: 0.041116\n",
      "Train Epoch: 3 [45568/60000 (75%)]\tLoss: 0.044716\n",
      "\n",
      "Test set: Average loss: 0.0488, Accuracy: 9839/10000 (98%)\n",
      "\n",
      "Train Epoch: 4 [14848/60000 (25%)]\tLoss: 0.028931\n",
      "Train Epoch: 4 [30208/60000 (50%)]\tLoss: 0.036014\n",
      "Train Epoch: 4 [45568/60000 (75%)]\tLoss: 0.041002\n",
      "\n",
      "Test set: Average loss: 0.0424, Accuracy: 9869/10000 (99%)\n",
      "\n",
      "Train Epoch: 5 [14848/60000 (25%)]\tLoss: 0.046034\n",
      "Train Epoch: 5 [30208/60000 (50%)]\tLoss: 0.024564\n",
      "Train Epoch: 5 [45568/60000 (75%)]\tLoss: 0.047217\n",
      "\n",
      "Test set: Average loss: 0.0398, Accuracy: 9852/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = ConvNet().to(DEVICE)#如果你的电脑有GPU，这行代码将模型转到GPU上，方便加速计算\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "#在训练集上迭代更新网络参数\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    # batch_idx是代表第几个batch\n",
    "    # data是图像数据，shape为(512,1,28,28)\n",
    "    # target是标签值，shape为(512),其中每一个元素为一个整数值，代表类别标签\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)#将数据从内存转到GPU的显存中（如果有GPU）\n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(data)\n",
    "        loss = F.nll_loss(output, target)#内置损失函数，文档：https://pytorch.org/docs/stable/nn.functional.html?highlight=nll_loss#torch.nn.functional.nll_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if(batch_idx+1)%30 == 0: \n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "#在测试集上测试网络性能\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()#测试时设置为evaluate模式，这样使用训练后得到的权重来测试网络性能\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)#正向计算预测值\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # 将一批的损失相加\n",
    "            pred = output.max(1, keepdim=True)[1] # 找到概率最大的下标\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()#找到正确的预测值\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "            \n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(model, DEVICE, train_loader, optimizer, epoch)\n",
    "    test(model, DEVICE, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test\n",
    "- 这里为你展示了测试集中的第一个图片是数字7，并且网络预测的结果也是7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred:tensor([7], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "x,y=test_loader.dataset[0]\n",
    "\n",
    "print('label:{}'.format(y))\n",
    "plt.imshow(x[0,:,:].numpy())\n",
    "plt.show()\n",
    "\n",
    "x=x.view(1,1,28,28).to(DEVICE)\n",
    "#这个y_pred的shape是(1,10)，代表1个数据，属于10类的概率，概率最高的那个类被认为是预测出来的类\n",
    "y_pred=model.forward(x)\n",
    "y_pred=torch.argmax(y_pred,dim=1)\n",
    "\n",
    "print('y_pred:{}'.format(y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
